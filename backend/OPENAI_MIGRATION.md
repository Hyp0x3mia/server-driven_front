# âœ… å·²æ›´æ–°ä¸º OpenAI å…¼å®¹æ ¼å¼

## ðŸ”§ ä¸»è¦å˜æ›´

### 1. ç»Ÿä¸€çš„ LLM å®¢æˆ·ç«¯

**æ–°å¢žæ–‡ä»¶**: [llm/client.py](llm/client.py)

```python
# ç»Ÿä¸€çš„ LLM å®¢æˆ·ç«¯ï¼Œæ”¯æŒæ‰€æœ‰ OpenAI å…¼å®¹ API
from llm.client import create_llm_from_env

# è‡ªåŠ¨ä»ŽçŽ¯å¢ƒå˜é‡åŠ è½½é…ç½®
llm = create_llm_from_env()
```

### 2. æ›´æ–°çš„ Agent æ–‡ä»¶

æ‰€æœ‰ agent å·²æ›´æ–°ä¸ºä½¿ç”¨ OpenAI å…¼å®¹ APIï¼š

- âœ… [agents/planner.py](agents/planner.py)
- âœ… [agents/content_expert.py](agents/content_expert.py)
- âœ… [agents/visual_director.py](agents/visual_director.py)
- âœ… [agents/content_expert_enhanced.py](agents/content_expert_enhanced.py)

### 3. æ›´æ–°çš„ä¾èµ–

**requirements.txt** å·²æ›´æ–°ï¼š
- âŒ ç§»é™¤ `langchain-anthropic`
- âŒ ç§»é™¤ `anthropic`
- âœ… æ·»åŠ  `langchain-openai>=0.2.0`

## ðŸš€ å¿«é€Ÿå¼€å§‹

### æ–¹å¼ 1: çŽ¯å¢ƒå˜é‡ï¼ˆæŽ¨èï¼‰

```bash
# GLM (æŽ¨èç”¨äºŽä¸­æ–‡)
export GLM_API_KEY="your-glm-api-key"
export GLM_BASE_URL="https://open.bigmodel.cn/api/paas/v4/"
export GLM_MODEL="glm-4-flash"

# SiliconFlow
export LLM_API_KEY="your-api-key"
export LLM_BASE_URL="https://api.siliconflow.cn/v1"
export LLM_MODEL="deepseek-ai/DeepSeek-V3"

# æˆ–ä½¿ç”¨ OpenAI æ ‡å‡†å˜é‡
export OPENAI_API_KEY="your-openai-key"
export OPENAI_BASE_URL="https://api.openai.com/v1"
```

### æ–¹å¼ 2: .env æ–‡ä»¶

```bash
# GLM
cat > .env << 'EOF'
GLM_API_KEY=your-glm-api-key
GLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4/
GLM_MODEL=glm-4-flash
EOF

# SiliconFlow
cat > .env << 'EOF'
LLM_API_KEY=your-siliconflow-key
LLM_BASE_URL=https://api.siliconflow.cn/v1
LLM_MODEL=deepseek-ai/DeepSeek-V3
EOF

# æˆ– OpenAI
cat > .env << 'EOF'
OPENAI_API_KEY=your-openai-key
OPENAI_BASE_URL=https://api.openai.com/v1
EOF
```

## ðŸ” éªŒè¯é…ç½®

```bash
# 1. å®‰è£…/æ›´æ–°ä¾èµ–
pip install -r requirements.txt

# 2. æµ‹è¯•é…ç½®
python test_imports.py

# 3. æµ‹è¯• LLM è¿žæŽ¥
python setup_llm.py
# é€‰æ‹© 3 - æµ‹è¯•å½“å‰é…ç½®
```

## ðŸ“ æ–°å¢žæ–‡ä»¶

```
backend/
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ client.py              # ç»Ÿä¸€çš„ LLM å®¢æˆ·ç«¯ â­
â”œâ”€â”€ OPENAI_CONFIG.md           # OpenAI é…ç½®æŒ‡å— â­
â””â”€â”€ setup_llm.py               # é…ç½®åŠ©æ‰‹ â­
```

## ðŸŽ¯ æ”¯æŒçš„ API

| æœåŠ¡å•† | Base URL | æŽ¨èæ¨¡åž‹ | è¯´æ˜Ž |
|--------|-----------|---------|------|
| **GLM (æ™ºè°±)** | `https://open.bigmodel.cn/api/paas/v4/` | `glm-4-flash` | æŽ¨èç”¨äºŽä¸­æ–‡ |
| **SiliconFlow** | `https://api.siliconflow.cn/v1` | `deepseek-ai/DeepSeek-V3` | ä¸­æ–‡ä¼˜åŒ– |
| **OpenAI** | `https://api.openai.com/v1` | `gpt-4o` | å®˜æ–¹ API |
| **Azure OpenAI** | `https://your-resource.openai.azure.com/` | `gpt-4o` | Azure ç‰ˆ |

## ðŸ’¡ é…ç½®ç¤ºä¾‹

### GLMï¼ˆä¸­æ–‡æŽ¨èï¼‰

```bash
GLM_API_KEY=your-glm-api-key
GLM_BASE_URL=https://open.bigmodel.cn/api/paas/v4/
GLM_MODEL=glm-4-flash
LLM_TEMPERATURE=0.3
```

### SiliconFlowï¼ˆä¸­æ–‡ä¼˜åŒ–ï¼‰

```bash
LLM_API_KEY=sk-xxxxxxxxxxxxx
LLM_BASE_URL=https://api.siliconflow.cn/v1
LLM_MODEL=deepseek-ai/DeepSeek-V3
LLM_TEMPERATURE=0.3
```

### OpenAIï¼ˆé€šç”¨ï¼‰

```bash
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxx
OPENAI_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4o
```

### è‡ªå®šä¹‰æœåŠ¡

ä»»ä½• OpenAI å…¼å®¹çš„ APIï¼š

```bash
LLM_API_KEY=your-key
LLM_BASE_URL=https://your-api.com/v1
LLM_MODEL=your-model
```

## ðŸ“Š ä»£ç å¯¹æ¯”

### ä¹‹å‰ï¼ˆAnthropicï¼‰

```python
from langchain_anthropic import ChatAnthropic

llm = ChatAnthropic(
    model_name="claude-sonnet-4-20250514",
    temperature=0.3
)
```

### çŽ°åœ¨ï¼ˆOpenAI å…¼å®¹ï¼‰

```python
from llm.client import create_llm_from_env

llm = create_llm_from_env()
# è‡ªåŠ¨ä»ŽçŽ¯å¢ƒå˜é‡åŠ è½½é…ç½®
# æ”¯æŒ OpenAIã€SiliconFlowã€Azure ç­‰
```

## ðŸŽ‰ ä¸»è¦ä¼˜åŠ¿

1. **çµæ´»æ€§** - è½»æ¾åˆ‡æ¢ä¸åŒçš„ API æä¾›å•†
2. **å…¼å®¹æ€§** - æ ‡å‡†çš„ OpenAI æ ¼å¼
3. **ç®€å•æ€§** - åªéœ€è®¾ç½® 3 ä¸ªçŽ¯å¢ƒå˜é‡
4. **æˆæœ¬ä¼˜åŒ–** - é€‰æ‹©æ€§ä»·æ¯”æœ€é«˜çš„æœåŠ¡
5. **ä¸­æ–‡æ”¯æŒ** - GLM å’Œ SiliconFlow å¯¹ä¸­æ–‡ä¼˜åŒ–
6. **å›½äº§æ”¯æŒ** - GLM æ˜¯æ™ºè°± AI çš„å›½äº§å¤§æ¨¡åž‹

## ðŸ“š ç›¸å…³æ–‡æ¡£

- **[OPENAI_CONFIG.md](OPENAI_CONFIG.md)** - è¯¦ç»†é…ç½®æŒ‡å—
- **[llm/client.py](llm/client.py)** - LLM å®¢æˆ·ç«¯å®žçŽ°
- **[setup_llm.py](setup_llm.py)** - é…ç½®åŠ©æ‰‹
- **[.env.example](.env.example)** - çŽ¯å¢ƒå˜é‡æ¨¡æ¿

## ðŸš€ ç«‹å³å¼€å§‹

```bash
cd backend

# 1. é…ç½® APIï¼ˆé€‰æ‹©ä¸€ç§æ–¹å¼ï¼‰
# GLM (æŽ¨èç”¨äºŽä¸­æ–‡)
export GLM_API_KEY="your-glm-key"
export GLM_BASE_URL="https://open.bigmodel.cn/api/paas/v4/"
export GLM_MODEL="glm-4-flash"

# SiliconFlow
export LLM_API_KEY="your-key"
export LLM_BASE_URL="https://api.siliconflow.cn/v1"
export LLM_MODEL="deepseek-ai/DeepSeek-V3"

# æˆ–ä½¿ç”¨é…ç½®åŠ©æ‰‹
python setup_llm.py

# 2. å®‰è£…ä¾èµ–ï¼ˆå¦‚æžœéœ€è¦ï¼‰
pip install -r requirements.txt

# 3. æµ‹è¯•
python test_imports.py

# 4. è¿è¡Œç¤ºä¾‹
python example_knowledge_path.py
```

## âœ¨ å®Œå…¨å…¼å®¹

- âœ… ä¿ç•™æ‰€æœ‰åŽŸæœ‰åŠŸèƒ½
- âœ… æ”¯æŒä½ çš„çŸ¥è¯†è·¯å¾„æ ¼å¼
- âœ… å™è¿°åŒ–ä¸Šä¸‹æ–‡ç”Ÿæˆ
- âœ… æ™ºèƒ½ç»„ä»¶é€‰æ‹©
- âœ… å‰ç«¯å…¼å®¹è¾“å‡º

çŽ°åœ¨å¯ä»¥ä½¿ç”¨ä»»ä½• OpenAI å…¼å®¹çš„ API äº†ï¼ðŸŽ‰
