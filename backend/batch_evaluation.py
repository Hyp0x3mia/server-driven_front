#!/usr/bin/env python3
"""
æ‰¹é‡ç”Ÿæˆè¯„æµ‹é›†å†…å®¹

è‡ªåŠ¨ä¸ºæ‰€æœ‰è¯„æµ‹é›†æ ·æœ¬ç”Ÿæˆæ•™è‚²å†…å®¹ï¼Œå¹¶ä¿å­˜ç»“æœã€‚
"""

import os
import sys
import time
import json
from datetime import datetime
from dotenv import load_dotenv

load_dotenv()

# Add backend to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.schemas import (
    KnowledgePath,
    KnowledgePoint,
    CognitiveLevel,
    GenerationRequest,
    DifficultyLevel
)
from workflows.pipeline import create_pipeline
from agents.assembler import AssemblerAgent
from evaluation_set import EVALUATION_SETS


def convert_evaluation_set_to_request(eval_set):
    """å°†è¯„æµ‹é›†è½¬æ¢ä¸ºç”Ÿæˆè¯·æ±‚"""
    knowledge_points = []

    for kp_data in eval_set["knowledge_points"]:
        # åˆ›å»ºçŸ¥è¯†ç‚¹å¯¹è±¡
        kp = KnowledgePoint(
            knowledge_id=kp_data["knowledge_id"],
            name=kp_data["name"],
            description=kp_data["description"],
            domain=kp_data["domain"],
            subdomain=kp_data["subdomain"],
            difficulty=kp_data["difficulty"],
            cognitive_level=CognitiveLevel(kp_data["cognitive_level"]),
            importance=kp_data["importance"],
            abstraction=kp_data["abstraction"],
            estimated_time=kp_data["estimated_time"],
            is_key_point=kp_data["is_key_point"],
            is_difficult=kp_data["is_difficult"],
            prerequisites=kp_data["prerequisites"],
            successors=kp_data["successors"],
            keywords=kp_data["keywords"],
            application_scenarios=kp_data["application_scenarios"],
            common_misconceptions=kp_data["common_misconceptions"],
            mastery_criteria=kp_data["mastery_criteria"]
        )
        knowledge_points.append(kp)

    # åˆ›å»ºçŸ¥è¯†è·¯å¾„
    knowledge_path = KnowledgePath(
        knowledge_points=knowledge_points,
        domain=eval_set["domain"],
        target_audience=eval_set["target_audience"]
    )

    # åˆ›å»ºç”Ÿæˆè¯·æ±‚
    request = GenerationRequest(
        knowledge_path=knowledge_path,
        target_audience=eval_set["target_audience"],
        difficulty=DifficultyLevel(eval_set["difficulty"]),
        user_intent=eval_set["user_intent"],
        custom_title=eval_set["topic"],
        page_id=eval_set["set_id"]
    )

    return request


def evaluate_components(generated_schema, expected_components):
    """è¯„ä¼°ç”Ÿæˆçš„ç»„ä»¶æ˜¯å¦ç¬¦åˆé¢„æœŸ"""
    generated_components = set()
    for block in generated_schema.components:
        generated_components.add(block.type.value)

    expected = set(expected_components)

    # è®¡ç®—åŒ¹é…åº¦
    matched = generated_components & expected
    coverage = len(matched) / len(expected) if expected else 0

    return {
        "expected": list(expected),
        "generated": list(generated_components),
        "matched": list(matched),
        "missing": list(expected - generated_components),
        "unexpected": list(generated_components - expected),
        "coverage": coverage
    }


def run_evaluation(eval_set, pipeline):
    """è¿è¡Œå•ä¸ªè¯„æµ‹é›†çš„ç”Ÿæˆ"""
    print(f"\n{'='*70}")
    print(f"ğŸ¯ è¯„æµ‹é›†: {eval_set['set_id']} - {eval_set['topic']}")
    print(f"{'='*70}")
    print(f"   é¢†åŸŸ: {eval_set['domain']}")
    print(f"   å—ä¼—: {eval_set['target_audience']}")
    print(f"   éš¾åº¦: {eval_set['difficulty']}")
    print(f"   çŸ¥è¯†ç‚¹æ•°: {len(eval_set['knowledge_points'])}")
    print(f"   é¢„æœŸç»„ä»¶: {', '.join(eval_set['expected_components'])}")

    start_time = time.time()

    try:
        # è½¬æ¢ä¸ºè¯·æ±‚
        request = convert_evaluation_set_to_request(eval_set)

        # è¿è¡Œ pipeline
        response = pipeline.run(request)

        elapsed_time = time.time() - start_time

        if response.success:
            # è¯„ä¼°ç»„ä»¶
            component_eval = evaluate_components(
                response.page_schema,
                eval_set["expected_components"]
            )

            print(f"\nâœ… ç”ŸæˆæˆåŠŸï¼")
            print(f"   ç”¨æ—¶: {elapsed_time:.2f}ç§’")
            print(f"   Tokens: {response.tokens_used}")
            print(f"   ç« èŠ‚æ•°: {len(response.page_schema.sections)}")
            print(f"   ç»„ä»¶æ•°: {len(response.page_schema.components)}")

            print(f"\nğŸ“Š ç»„ä»¶è¯„ä¼°:")
            print(f"   è¦†ç›–ç‡: {component_eval['coverage']*100:.0f}%")
            print(f"   åŒ¹é…: {', '.join(component_eval['matched']) if component_eval['matched'] else 'æ— '}")
            if component_eval['missing']:
                print(f"   ç¼ºå¤±: {', '.join(component_eval['missing'])}")
            if component_eval['unexpected']:
                print(f"   é¢å¤–: {', '.join(component_eval['unexpected'])}")

            # ä¿å­˜ç»“æœ
            result = {
                "set_id": eval_set["set_id"],
                "topic": eval_set["topic"],
                "domain": eval_set["domain"],
                "success": True,
                "generation_time": elapsed_time,
                "tokens_used": response.tokens_used,
                "sections": len(response.page_schema.sections),
                "components": len(response.page_schema.components),
                "component_evaluation": component_eval,
                "generated_at": datetime.now().isoformat()
            }

            # å¯¼å‡º JSON
            output_dir = "evaluation_results"
            os.makedirs(output_dir, exist_ok=True)
            output_path = f"{output_dir}/{eval_set['set_id']}.json"

            assembler = AssemblerAgent()
            assembler.export_to_json(response.page_schema, output_path)

            return result
        else:
            print(f"\nâŒ ç”Ÿæˆå¤±è´¥: {response.error}")
            return {
                "set_id": eval_set["set_id"],
                "success": False,
                "error": response.error,
                "generated_at": datetime.now().isoformat()
            }

    except Exception as e:
        elapsed_time = time.time() - start_time
        print(f"\nâŒ å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

        return {
            "set_id": eval_set["set_id"],
            "success": False,
            "error": str(e),
            "elapsed_time": elapsed_time,
            "generated_at": datetime.now().isoformat()
        }


def main():
    """æ‰¹é‡è¿è¡Œæ‰€æœ‰è¯„æµ‹é›†"""
    print("\n" + "="*70)
    print("ğŸš€ æ‰¹é‡ç”Ÿæˆè¯„æµ‹é›†å†…å®¹")
    print("="*70)

    # æ£€æŸ¥ API key
    api_key = os.getenv("GLM_API_KEY") or os.getenv("LLM_API_KEY") or os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("\nâŒ é”™è¯¯: æœªè®¾ç½® LLM API Key")
        print("\nè¯·è®¾ç½®ä»¥ä¸‹ä¹‹ä¸€:")
        print("  export GLM_API_KEY='your-glm-key'")
        print("  export LLM_API_KEY='your-api-key'")
        print("  export OPENAI_API_KEY='your-openai-key'")
        return

    # åˆ›å»º pipeline
    print("\nğŸ”§ åˆå§‹åŒ– Pipeline...")
    pipeline = create_pipeline()
    print("âœ… Pipeline åˆå§‹åŒ–å®Œæˆ")

    # é€‰æ‹©è¯„æµ‹é›†
    print(f"\nğŸ“‹ å¯ç”¨è¯„æµ‹é›†: {len(EVALUATION_SETS)} ä¸ª")
    for i, eval_set in enumerate(EVALUATION_SETS, 1):
        print(f"  {i}. {eval_set['set_id']} - {eval_set['topic']} ({eval_set['domain']})")

    choice = input("\nè¿è¡Œå“ªä¸ªè¯„æµ‹é›†? (1-10, æˆ– 'all'): ").strip().lower()

    results = []
    start_time = time.time()

    if choice == "all":
        # è¿è¡Œæ‰€æœ‰è¯„æµ‹é›†
        for i, eval_set in enumerate(EVALUATION_SETS, 1):
            print(f"\nè¿›åº¦: {i}/{len(EVALUATION_SETS)}")
            result = run_evaluation(eval_set, pipeline)
            results.append(result)

            # ä¿å­˜ä¸­é—´ç»“æœ
            with open("evaluation_results/_latest.json", "w", encoding="utf-8") as f:
                json.dump(results, f, ensure_ascii=False, indent=2)

    elif choice.isdigit() and 1 <= int(choice) <= len(EVALUATION_SETS):
        # è¿è¡Œå•ä¸ªè¯„æµ‹é›†
        eval_set = EVALUATION_SETS[int(choice) - 1]
        result = run_evaluation(eval_set, pipeline)
        results.append(result)
    else:
        print("æ— æ•ˆé€‰æ‹©")
        return

    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    total_time = time.time() - start_time

    print("\n" + "="*70)
    print("ğŸ“Š è¯„æµ‹æ€»ç»“")
    print("="*70)

    successful = sum(1 for r in results if r.get("success", False))
    failed = len(results) - successful

    print(f"\næ€»è¯„æµ‹é›†æ•°: {len(results)}")
    print(f"âœ… æˆåŠŸ: {successful}")
    print(f"âŒ å¤±è´¥: {failed}")
    print(f"â±ï¸  æ€»ç”¨æ—¶: {total_time:.1f}ç§’ ({total_time/60:.1f}åˆ†é’Ÿ)")

    if successful > 0:
        total_tokens = sum(r.get("tokens_used", 0) for r in results if r.get("success"))
        avg_time = sum(r.get("generation_time", 0) for r in results if r.get("success")) / successful

        print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡:")
        print(f"   æ€» Tokens: {total_tokens}")
        print(f"   å¹³å‡ç”¨æ—¶: {avg_time:.1f}ç§’")

        # ç»„ä»¶è¦†ç›–ç»Ÿè®¡
        all_coverage = [r.get("component_evaluation", {}).get("coverage", 0)
                       for r in results if r.get("success")]
        if all_coverage:
            avg_coverage = sum(all_coverage) / len(all_coverage)
            print(f"   å¹³å‡ç»„ä»¶è¦†ç›–ç‡: {avg_coverage*100:.1f}%")

    # ä¿å­˜å®Œæ•´ç»“æœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    results_file = f"evaluation_results/batch_results_{timestamp}.json"
    with open(results_file, "w", encoding="utf-8") as f:
        json.dump({
            "summary": {
                "total": len(results),
                "successful": successful,
                "failed": failed,
                "total_time": total_time,
                "generated_at": datetime.now().isoformat()
            },
            "results": results
        }, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    print(f"ğŸ’¾ ç”Ÿæˆçš„å†…å®¹ä¿å­˜åœ¨: evaluation_results/")

    # æ˜¾ç¤ºå¤±è´¥çš„è¯„æµ‹é›†
    if failed > 0:
        print(f"\nâŒ å¤±è´¥çš„è¯„æµ‹é›†:")
        for result in results:
            if not result.get("success", False):
                print(f"   - {result['set_id']}: {result.get('error', 'Unknown error')}")


if __name__ == "__main__":
    main()
