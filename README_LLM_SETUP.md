# ğŸ‰ LLM é›†æˆé…ç½®å®Œæˆï¼

## å¿«é€Ÿå¼€å§‹ï¼ˆ3 æ­¥é…ç½®ï¼‰

### 1ï¸âƒ£ åˆ›å»ºé…ç½®æ–‡ä»¶

```bash
cp .env.example .env
```

### 2ï¸âƒ£ ç¼–è¾‘ `.env` æ–‡ä»¶

**ä½¿ç”¨ OpenAI å…¼å®¹ APIï¼ˆæ¨èï¼‰ï¼š**
```env
VITE_LLM_PROVIDER=customOpenAI
VITE_CUSTOM_API_KEY=sk-your-api-key-here
VITE_CUSTOM_BASE_URL=https://your-api-endpoint.com/v1
VITE_CUSTOM_MODEL=gpt-3.5-turbo
```

**æˆ–ä½¿ç”¨æœ¬åœ° Ollamaï¼ˆå…è´¹ï¼‰ï¼š**
```env
VITE_LLM_PROVIDER=ollama
```

### 3ï¸âƒ£ å¯åŠ¨å¹¶ä½¿ç”¨

```bash
npm run dev
```

æ‰“å¼€æµè§ˆå™¨æ§åˆ¶å°ï¼ˆF12ï¼‰ï¼Œç›´æ¥å¼€å§‹ç”Ÿæˆï¼š

```javascript
const data = await llm.generate({ topic: 'ä½ æ„Ÿå…´è¶£çš„ä¸»é¢˜' })
llm.download(data, 'output.json')
```

## ğŸ“ æ–‡ä»¶è¯´æ˜

### æ ¸å¿ƒæ–‡ä»¶

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| [`src/lib/llm-config.ts`](src/lib/llm-config.ts:1) | **ä¸»è¦é…ç½®æ–‡ä»¶** - åœ¨è¿™é‡Œç›´æ¥é…ç½® API |
| [`.env.example`](.env.example:1) | ç¯å¢ƒå˜é‡æ¨¡æ¿ |
| [`src/lib/llm-helper.ts`](src/lib/llm-helper.ts:1) | æµè§ˆå™¨æ§åˆ¶å°æ¥å£ |
| [`src/lib/llm-client.ts`](src/lib/llm-client.ts:1) | LLM å®¢æˆ·ç«¯ç±»å‹å®šä¹‰ |
| [`src/lib/llm-client-impl.ts`](src/lib/llm-client-impl.ts:1) | LLM å®¢æˆ·ç«¯å®ç° |
| [`src/lib/agent-generator.ts`](src/lib/agent-generator.ts:1) | Agent ç”Ÿæˆå™¨ |

### æ–‡æ¡£

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| [`LLM_CONFIG_GUIDE.md`](LLM_CONFIG_GUIDE.md:1) | **é…ç½®æŒ‡å—** - è¯¦ç»†çš„é…ç½®è¯´æ˜ |
| [`LLM_INTEGRATION.md`](LLM_INTEGRATION.md:1) | ä½¿ç”¨æŒ‡å— - API å‚è€ƒ |
| [`AUTOMATED_TESTING.md`](AUTOMATED_TESTING.md:1) | æµ‹è¯•æŒ‡å— |

## ğŸ¯ ä¸¤ç§é…ç½®æ–¹å¼

### æ–¹å¼ Aï¼šä½¿ç”¨ .env æ–‡ä»¶ï¼ˆæ¨èï¼‰

1. å¤åˆ¶ `.env.example` ä¸º `.env`
2. å¡«å…¥ä½ çš„ API é…ç½®
3. åˆ·æ–°é¡µé¢è‡ªåŠ¨åŠ è½½

**ä¼˜ç‚¹ï¼š**
- âœ… ä¸éœ€è¦æ”¹ä»£ç 
- âœ… å®‰å…¨ï¼ˆä¸ä¼šè¢«æäº¤åˆ° Gitï¼‰
- âœ… æ”¯æŒå¤šç¯å¢ƒ

### æ–¹å¼ Bï¼šç›´æ¥ä¿®æ”¹ä»£ç 

ç¼–è¾‘ [`src/lib/llm-config.ts`](src/lib/llm-config.ts:62)ï¼š

```typescript
export function getCurrentLLMConfig() {
  const provider = 'customOpenAI';  // ğŸ‘ˆ æ”¹è¿™é‡Œ

  return llmConfig[provider] || llmConfig.openai;
}
```

ç„¶ååœ¨ `llmConfig` ä¸­å¡«å…¥ä½ çš„ API ä¿¡æ¯ï¼š

```typescript
customOpenAI: {
  apiKey: 'sk-çœŸå®å¯†é’¥',        // ğŸ‘ˆ å¡«è¿™é‡Œ
  baseURL: 'https://çœŸå®åœ°å€/v1',  // ğŸ‘ˆ å¡«è¿™é‡Œ
  model: 'gpt-3.5-turbo'
}
```

**ä¼˜ç‚¹ï¼š**
- âœ… ç®€å•ç›´æ¥
- âœ… é€‚åˆå¿«é€Ÿæµ‹è¯•

## ğŸ”Œ OpenAI å…¼å®¹ API é…ç½®

### é€šç”¨æ ¼å¼

ä»»ä½•å…¼å®¹ OpenAI API æ ¼å¼çš„æœåŠ¡éƒ½å¯ä»¥ä½¿ç”¨ï¼š

```typescript
{
  apiKey: 'your-api-key',
  baseURL: 'https://api-endpoint.com/v1',  // å…³é”®
  model: 'model-name'
}
```

### å¸¸è§æœåŠ¡é…ç½®

| æœåŠ¡ | baseURL | model |
|------|---------|-------|
| **OpenAI** | `https://api.openai.com/v1` | `gpt-3.5-turbo` |
| **OneAPI** | `https://your-oneapi.com/v1` | `gpt-3.5-turbo` |
| **DeepSeek** | `https://api.deepseek.com/v1` | `deepseek-chat` |
| **Moonshot** | `https://api.moonshot.cn/v1` | `moonshot-v1-8k` |
| **æ™ºè°± AI** | `https://open.bigmodel.cn/api/paas/v4` | `glm-4` |
| **Ollama** | `http://localhost:11434` | `llama3` |

## ğŸš€ ä½¿ç”¨ç¤ºä¾‹

### åŸºç¡€ä½¿ç”¨

```javascript
// 1. é…ç½®ï¼ˆå¦‚æœç”¨ .env åˆ™è‡ªåŠ¨é…ç½®ï¼‰
llm.configure({
  apiKey: 'sk-...',
  baseURL: 'https://api.xxx.com/v1',
  model: 'gpt-3.5-turbo'
})

// 2. ç”Ÿæˆ
const data = await llm.generate({
  topic: 'æœºå™¨å­¦ä¹ åŸºç¡€',
  agentType: 'knowledge'
})

// 3. ä¸‹è½½
llm.download(data, 'ml-basics.json')
```

### é«˜çº§ä½¿ç”¨

```javascript
// ç”Ÿæˆå¹¶è½¬æ¢
const { simplified, converted } = await llm.generateAndConvert({
  topic: 'React Hooks',
  agentType: 'code',
  difficulty: 'advanced',
  additionalInstructions: 'åŒ…å« useMemo, useCallback ç¤ºä¾‹'
})

// ä¸‹è½½è½¬æ¢åçš„æ ¼å¼
llm.download(converted, 'react-hooks-converted.json')
```

## âš ï¸ é‡è¦æç¤º

### å®‰å…¨æ€§

- âŒ **ä¸è¦**å°† `.env` æ–‡ä»¶æäº¤åˆ° Git
- âœ… **ä½¿ç”¨**ç¯å¢ƒå˜é‡æˆ– secrets æœåŠ¡
- âœ… **å®šæœŸ**è½®æ¢ API Key

### .gitignore é…ç½®

ç¡®ä¿ `.gitignore` åŒ…å«ï¼š
```gitignore
.env
.env.local
.env.production
```

### éªŒè¯é…ç½®

å¯åŠ¨åæ£€æŸ¥æµè§ˆå™¨æ§åˆ¶å°ï¼š
```
âœ… æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶ï¼Œæ­£åœ¨è‡ªåŠ¨é…ç½®...
âœ… LLM é…ç½®æˆåŠŸ
   æä¾›å•†: customOpenAI
   æ¨¡å‹: gpt-3.5-turbo
âœ… è‡ªåŠ¨é…ç½®æˆåŠŸï¼
```

## ğŸ“ éœ€è¦å¸®åŠ©ï¼Ÿ

1. **æŸ¥çœ‹é…ç½®æŒ‡å—**ï¼š[LLM_CONFIG_GUIDE.md](LLM_CONFIG_GUIDE.md:1)
2. **æŸ¥çœ‹ä½¿ç”¨æ–‡æ¡£**ï¼š[LLM_INTEGRATION.md](LLM_INTEGRATION.md:1)
3. **æ£€æŸ¥é”™è¯¯ä¿¡æ¯**ï¼šæµè§ˆå™¨æ§åˆ¶å°

## ğŸŠ ç°åœ¨å¼€å§‹ä½¿ç”¨ï¼

```bash
# 1. é…ç½®
cp .env.example .env
# ç¼–è¾‘ .env å¡«å…¥ä½ çš„ API

# 2. å¯åŠ¨
npm run dev

# 3. æ‰“å¼€æµè§ˆå™¨æ§åˆ¶å°ï¼Œè¿è¡Œï¼š
const data = await llm.generate({ topic: 'æµ‹è¯•' })
```

ç¥ä½ ä½¿ç”¨æ„‰å¿«ï¼ğŸš€
