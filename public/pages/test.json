{
  "page_id": "nlp-comprehensive-test",
  "pageMode": "interactive-article",
  "title": "自然语言处理全面测试",
  "summary": "测试所有组件：Hero、Flashcard、CardGrid、Timeline",
  "sections": [
    {
      "section_id": "nlp-intro",
      "sectionType": "Article",
      "title": "自然语言处理学习路径",
      "layoutIntent": "prose-view",
      "pedagogicalGoal": "全面测试所有组件类型",
      "blocks": [
        {
          "type": "Hero",
          "role": "header",
          "content": {
            "title": "🤖 自然语言处理 (NLP)",
            "subtitle": "从基础概念到大语言模型的完整学习路径",
            "features": [
              "📚 基础概念与历史发展",
              "🧠 文本分析与语义表示",
              "🌐 核心NLP任务详解",
              "💬 对话系统与大模型应用"
            ]
          }
        },
        {
          "type": "Flashcard",
          "id": "nlp-flashcard-1",
          "front": {
            "title": "快速自测",
            "content": "什么是**自然语言处理 (NLP)**？\n\n它主要解决哪些问题？"
          },
          "back": {
            "title": "答案",
            "content": "**自然语言处理 (NLP)** 是引导机器模拟和延伸人类语言能力的基础性和关键性研究方向。\n\n**主要任务：**\n\n- 自然语言的机器表示\n- 文本分析与理解\n- 语言生成\n- 广泛应用于各行各业和日常生活"
          }
        },
        {
          "type": "CardGrid",
          "role": "knowledge-cards",
          "content": {
            "title": "NLP 基础概念",
            "items": [
              {
                "name": "自然语言处理概述",
                "description": "自然语言处理是人工智能十分重要的研究领域，有漫长的发展历史、丰富的技术内涵和广泛的应用价值。",
                "keywords": ["自然语言处理", "人工智能", "大语言模型"],
                "common_misconceptions": ["NLP就是机器翻译", "NLP只能处理英文"]
              },
              {
                "name": "NLP的定义与作用",
                "description": "自然语言处理（NLP）是引导机器模拟和延伸人类语言能力的基础性和关键性研究方向，包括自然语言的机器表示、分析、理解、生成等。",
                "keywords": ["NLP", "机器表示", "分析", "理解", "生成"],
                "common_misconceptions": ["NLP可以完全理解人类语言", "NLP只处理文本"]
              },
              {
                "name": "文本向量表示",
                "description": "将长短不一的文本转化为长度一致的向量，以便进行统一处理，是文本分析的基础表示方法。",
                "keywords": ["文本向量", "统一表示", "特征提取"],
                "common_misconceptions": ["向量表示就是词袋模型", "向量维度越高越好"]
              },
              {
                "name": "文本分析",
                "description": "文本分析就是自然语言处理各项任务的基础，最终目标是使计算机理解和生成人类语言。从一个文本文档中抽取所需要的信息。",
                "keywords": ["文本分析", "语义理解", "信息抽取"],
                "common_misconceptions": ["文本分析就是分词", "分析结果总是准确的"]
              },
              {
                "name": "文本语义表示",
                "description": "解决自然语言处理领域的基本问题——什么是语义？学习计算机如何理解文本语义并进行计算。",
                "keywords": ["文本语义", "语义表示", "语义理解", "计算"],
                "common_misconceptions": ["语义就是字面意思", "语义表示只有一种方法"]
              },
              {
                "name": "文本分类",
                "description": "为给定的文本自动确定其所述的类别标签。文本可以是不同长度的句子、段落、文章，也可以是不同类型的新闻、邮件、评价等。",
                "keywords": ["文本分类", "类别标签", "监督学习"],
                "common_misconceptions": ["分类需要人工规则", "只能分两类"]
              }
            ]
          }
        },
        {
          "type": "Timeline",
          "role": "chronology",
          "content": {
            "title": "NLP 发展历程",
            "items": [
              {
                "year": "1956前",
                "label": "萌芽期",
                "title": "理论基础奠基",
                "description": "1936年图灵提出图灵机概念、1946年电子计算机诞生、1948年Shannon利用概率方法描述语言、1956年Chomsky提出上下文无关语法，开辟了基于规则和基于概率两种技术路线。",
                "keywords": ["图灵机", "Shannon", "Chomsky", "上下文无关语法"],
                "subdomain": "nlp-history"
              },
              {
                "year": "1957-1970",
                "label": "快速发展期",
                "title": "两大阵营形成",
                "description": "形成基于规则方法的符号派和基于概率方法的随机派：符号派以Chomsky为代表进行形式语言理论研究；随机派采用贝叶斯方法。",
                "keywords": ["符号派", "随机派", "贝叶斯方法", "形式语言理论"],
                "subdomain": "nlp-history"
              },
              {
                "year": "1971-1990",
                "label": "低谷期",
                "title": "理性主义与经验主义",
                "description": "AI领域聚焦推理和逻辑问题，符号派研究势头强于随机派，但计算能力限制导致实际应用受阻。",
                "keywords": ["符号派", "随机派", "逻辑推理"],
                "subdomain": "nlp-history"
              },
              {
                "year": "1990后",
                "label": "复苏繁荣期",
                "title": "统计方法与深度学习",
                "description": "互联网带来大量数据，统计方法兴起。随后深度学习革命，2013年Word2Vec，2017年Transformer，2018年BERT，2020年代大语言模型爆发。",
                "keywords": ["统计方法", "深度学习", "Transformer", "大语言模型"],
                "subdomain": "nlp-history"
              }
            ]
          }
        },
        {
          "type": "Flashcard",
          "id": "nlp-flashcard-2",
          "front": {
            "title": "技术路线对比",
            "content": "NLP发展过程中形成了哪两大技术阵营？它们的主要区别是什么？"
          },
          "back": {
            "title": "答案揭晓",
            "content": "## 两大阵营\n\n### 1. 符号派（规则方法）\n- **代表**：Chomsky\n- **方法**：形式语言理论、生成句法、形式逻辑\n- **特点**：基于语言规则和语法结构\n\n### 2. 随机派（概率方法）\n- **方法**：贝叶斯方法、统计模型\n- **特点**：基于数据驱动和概率计算\n\n> 在1957-1970快速发展期，符号派势头强于随机派。"
          }
        },
        {
          "type": "CardGrid",
          "role": "task-showcase",
          "content": {
            "title": "核心 NLP 任务",
            "items": [
              {
                "name": "情感分析",
                "description": "分析人们在文本中对产品、事件、话题等的意见、情绪或评价。从某种意义上讲，情感分析也是一种广义的文本分类。",
                "keywords": ["情感分析", "观点挖掘", "文本分类"],
                "common_misconceptions": ["情感分析只能识别正面负面", "不需要上下文"]
              },
              {
                "name": "文本摘要",
                "description": "将长文本进行压缩、归纳和总结，从而形成概括性短文本。分为抽取式摘要和生成式摘要。",
                "keywords": ["文本摘要", "抽取式", "生成式", "压缩"],
                "common_misconceptions": ["抽取式就是复制第一句", "生成式必须使用RNN"]
              },
              {
                "name": "机器翻译",
                "description": "机器在没有人工干预下完成从一种语言到另一种语言的转换。技术发展经历了基于规则、基于统计和基于深度神经网络三个阶段。",
                "keywords": ["机器翻译", "规则", "统计", "神经网络"],
                "common_misconceptions": ["翻译就是逐词替换", "统计方法已经被淘汰"]
              },
              {
                "name": "机器阅读理解",
                "description": "使机器具有从自然语言中理解和抽取关键信息，继而回答问题的能力。这是对人类语言处理能力的一种模仿。",
                "keywords": ["机器阅读理解", "信息抽取", "问答系统"],
                "common_misconceptions": ["阅读理解需要完全理解文本", "只能回答事实性问题"]
              },
              {
                "name": "对话系统",
                "description": "目标是使机器与人类进行流畅的有意义的对话。分为任务导向型对话系统（帮助完成具体任务）和非任务导向型对话系统（聊天娱乐）。",
                "keywords": ["对话系统", "任务导向", "聊天机器人", "交互"],
                "common_misconceptions": ["对话系统就是Siri", "非任务型没有实际用途"]
              }
            ]
          }
        },
        {
          "type": "Timeline",
          "role": "learning-path",
          "content": {
            "title": "NLP 学习路径推荐",
            "items": [
              {
                "label": "第一步",
                "title": "掌握基础概念",
                "description": "学习自然语言处理的定义、作用、发展历程。理解文本向量表示、语义表示等基础理论。",
                "keywords": ["基础", "定义", "历史", "向量表示"],
                "common_misconceptions": ["基础概念不重要", "可以直接学深度学习"]
              },
              {
                "label": "第二步",
                "title": "文本分析技术",
                "description": "深入理解文本分析的目的、过程及在NLP中的基础作用。学习特征提取、文本预处理等技术。",
                "keywords": ["文本分析", "特征提取", "预处理"],
                "common_misconceptions": ["文本分析就是分词", "预处理步骤可以跳过"]
              },
              {
                "label": "第三步",
                "title": "核心NLP任务",
                "description": "掌握文本分类、情感分析、文本摘要、机器翻译等经典任务的原理和方法。",
                "keywords": ["分类", "情感分析", "摘要", "翻译"],
                "common_misconceptions": ["所有任务都用同一种方法", "任务之间没有关联"]
              },
              {
                "label": "第四步",
                "title": "高级应用",
                "description": "学习机器阅读理解、对话系统、知识图谱等高级应用。了解Transformer、BERT等预训练模型。",
                "keywords": ["阅读理解", "对话系统", "Transformer", "BERT"],
                "common_misconceptions": ["预训练模型万能", "不需要领域知识"]
              },
              {
                "label": "第五步",
                "title": "大语言模型",
                "description": "深入学习GPT、LLaMA等大语言模型的原理、微调技术、提示工程和应用开发。",
                "keywords": ["大语言模型", "GPT", "微调", "提示工程"],
                "common_misconceptions": ["大模型不需要训练", "提示工程很简单", "模型越大越好"]
              }
            ]
          }
        },
        {
          "type": "Flashcard",
          "id": "nlp-flashcard-3",
          "front": {
            "title": "任务对比",
            "content": "**抽取式摘要** vs **生成式摘要**\n\n它们的本质区别是什么？"
          },
          "back": {
            "title": "答案揭晓",
            "content": "## 两种摘要方法对比\n\n### 📋 抽取式摘要\n- **方法**：直接从原文中选择重要的句子\n- **过程**：排序、重组\n- **优点**：简单快速，事实准确\n- **缺点**：可能不连贯，缺乏新意\n\n### ✍️ 生成式摘要\n- **方法**：机器理解完整原文后转述\n- **过程**：理解 + 生成\n- **优点**：自然流畅，可以概括\n- **缺点**：可能产生幻觉\n\n> 💡 实际应用中常结合两种方法。"
          }
        },
        {
          "type": "Cloze",
          "content": "自然语言处理（NLP）是引导机器{{模拟和延伸}}人类语言能力的基础性和关键性研究方向。NLP的发展经历了{{基于规则}}、{{基于统计}}和{{基于深度学习}}三个主要技术阶段。"
        },
        {
          "type": "Flashcard",
          "id": "code-flashcard-1",
          "front": {
            "title": "代码测试",
            "content": "## JavaScript 闭包\n\n下面代码的输出是什么？\n\n```javascript\nfor (var i = 0; i < 3; i++) {\n  setTimeout(() => console.log(i), 100);\n}\n```"
          },
          "back": {
            "title": "答案",
            "content": "## 输出结果\n\n```\n3\n3\n3\n```\n\n### 解释\n\n因为 `var` 是**函数作用域**，而不是块级作用域。所有三个 setTimeout 都引用同一个 `i` 变量。\n\n### 解决方案\n\n使用 `let`（块级作用域）或立即执行函数：\n\n```javascript\n// 方案1：使用 let\nfor (let i = 0; i < 3; i++) {\n  setTimeout(() => console.log(i), 100);\n}\n\n// 方案2：使用 IIFE\nfor (var i = 0; i < 3; i++) {\n  ((j) => setTimeout(() => console.log(j), 100))(i);\n}\n```"
          }
        },
        {
          "type": "Flashcard",
          "id": "code-flashcard-2",
          "front": {
            "title": "React Hooks",
            "content": "## 这段代码有什么问题？\n\n```javascript\nuseEffect(() => {\n  fetch(url).then(data => setData(data));\n}, []);\n```"
          },
          "back": {
            "title": "问题分析",
            "content": "## ❌ 缺少依赖项\n\n### 问题\n\n- 如果 `url` 是 props 或 state，使用的是**旧值**\n- ESLint 会警告：`React Hook useEffect has missing dependency: 'url'`\n\n### ✅ 正确写法\n\n```javascript\n// 方案1：添加依赖\nuseEffect(() => {\n  fetch(url).then(data => setData(data));\n}, [url]);\n\n// 方案2：使用 useCallback\nconst fetchData = useCallback(() => {\n  fetch(url).then(data => setData(data));\n}, [url]);\n\nuseEffect(() => {\n  fetchData();\n}, [fetchData]);\n```"
          }
        }
      ]
    }
  ]
}
